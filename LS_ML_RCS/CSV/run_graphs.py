# -*- coding: utf-8 -*-
"""CS565-final-graphs-v6.ipynb

Automatically generated by Colab.
Fixed by AI assistant for SilviaB24.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import re


# Directories
BASE_DIR_CSV = Path("CSV")   
BASE_DIR_CSTR = Path("Constraints") 
FACTORS = ["1.00", "0.90", "0.80", "0.70", "0.60", "0.50", "0.40", "0.30", "0.20", "0.10"]

# List of what variants to plot
WANTED_VARIANTS_1 = [
    "FALLS",       # Baseline Constraints
    "FDS",         # Force-Directed
    "LS",          # List Scheduling "Base"
    "LS_s0_p0",    # LS Standard
    "LS_s1_p1",    # LS Optimized
]

WANTED_VARIANTS_2 = [
    "LS",          # List Scheduling "Base"
    "LS_s0_p0",    # LS Standard
    "LS_s1_p1",    # LS Optimized
]

WANTED_VARIANTS_4 = [
    "LS",          # List Scheduling "Base"
    "LS_s1_p1",    # LS Optimized
]


# File paths
FDS_FILES = {
    "uniform": BASE_DIR_CSV / "Results_FDS_uniform_S0_P0.csv",
    "invdelay": BASE_DIR_CSV / "Results_FDS_invdelay_S0_P0.csv",
}

CONSTRAINT_FILES = {
    "uniform": BASE_DIR_CSTR / "constraints_uniform.txt",
    "invdelay": BASE_DIR_CSTR / "constraints_invdelay.txt",
}

# ============================================================
# 1. HELPER: DFG SIZES
# ============================================================

def normalize_dfg_name(dfg_name: str) -> str:
    if not isinstance(dfg_name, str): return "unknown"
    name = dfg_name
    if name.endswith(".txt"): name = name[:-4]
    for suff in ["_4type_invdelay", "_4type_uniform"]:
        if name.endswith(suff): name = name[: -len(suff)]
    return name

DFG_SIZES = {
    "example": 7, "hal": 11, "horner_bezier_surf_dfg__12": 18, "arf": 28,
    "motion_vectors_dfg__7": 32, "ewf": 34, "feedback_points_dfg__7": 53,
    "write_bmp_header_dfg__7": 106, "interpolate_aux_dfg__12": 108,
    "matmul_dfg__3": 109, "smooth_color_z_triangle_dfg__31": 197,
    "invert_matrix_general_dfg__3": 333, "h2v2_smooth_downsample_dfg__6": 51,
    "collapse_pyr_dfg__113": 56, "idctcol_dfg__3": 114,
    "jpeg_fdct_islow_dfg__6": 134, "random1": 601, "random2": 607,
    "random3": 806, "random4": 906, "random5": 1208, "random6": 1812,
    "random7": 2006,
}

def get_dfg_size(dfg_name: str) -> int:
    return DFG_SIZES.get(normalize_dfg_name(dfg_name), np.nan)

# ============================================================
# 2. LOADING
# ============================================================

def deduce_ls_variant(filename: str) -> str:
    name = filename.upper()
    
    # 1. Cerca prima le varianti specifiche
    if "_S0_P0" in name: return "LS_s0_p0"
    if "_S1_P1" in name: return "LS_s1_p1"
    
    # 2. Cerca LS generico
    # REGOLA: Deve avere "RESULTS_LS_" ma NON deve avere "_S" o "_P" nel nome
    if "RESULTS_LS_" in name:
        if "_S" not in name and "_P" not in name:
            return "LS"
        
    return "LS_other" # File ignorato (es. LS_S1_P0 se non ci serve)


def load_ls_results() -> pd.DataFrame:
    print(f"Scanning CSV folder: {BASE_DIR_CSV.resolve()}")
    files = list(BASE_DIR_CSV.glob("Results_LS_*.csv"))
    if not files:
        print("WARNING: No LS files found in CSV folder.")
        return pd.DataFrame()

    frames = []
    for path in files:
        try:
            df = pd.read_csv(path)
            fname = path.name
            if "uniform" in fname: mode = "uniform"
            elif "invdelay" in fname: mode = "invdelay"
            else: mode = "unknown"
            
            variant = deduce_ls_variant(fname)

            if variant in ["LS", "LS_s0_p0", "LS_s1_p1"]:
                print(f"  -> File '{fname}' identificato come: {variant}")
            else:
                print(f"  -> File '{fname}' scartato/altro ({variant})")
                
            df["mode"] = mode
            df["alg"] = "LS"
            df["variant"] = variant
            frames.append(df)
        except Exception as e:
            print(f"Error reading {path}: {e}")
            
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def load_fds_results() -> pd.DataFrame:
    frames = []
    for mode, path in FDS_FILES.items():
        if path.exists():
            df = pd.read_csv(path)
            df["mode"] = mode
            df["alg"] = "FDS"
            df["variant"] = "FDS"
            frames.append(df)
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def load_falls_baseline() -> pd.DataFrame:
    rows = []
    for mode, path in CONSTRAINT_FILES.items():
        if not path.exists():
            print(f"WARNING: Constraint file missing: {path}")
            continue
        with open(path, "r") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("//"): continue
                parts = line.split()
                try:
                    name = parts[0]
                    target = int(parts[1])
                    rows.append({
                        "DFG_Name": f"{name}_4type_{mode}",
                        "Target_Latency(FALLS)": target,
                        "Actual_Latency(Project)": target,
                        "Delta": 0,
                        "mode": mode,
                        "alg": "FALLS",
                        "variant": "FALLS"
                    })
                except: continue
    return pd.DataFrame(rows)

def load_all_results() -> pd.DataFrame:
    df = pd.concat([load_ls_results(), load_fds_results(), load_falls_baseline()], ignore_index=True)
    if not df.empty:
        df["DFG_base"] = df["DFG_Name"].apply(normalize_dfg_name)
        df["DFG_size"] = df["DFG_Name"].apply(get_dfg_size)
    return df

# ============================================================
# 3. PLOTS
# ============================================================

def plot_delta(df: pd.DataFrame, mode: str):
    sub = df[(df["mode"] == mode) & (df["variant"].isin(WANTED_VARIANTS_1))].copy()
    if sub.empty: return

    # Aggregate & Sort
    agg = sub.groupby(["DFG_base", "variant"], as_index=False)["Delta"].mean()
    agg = agg.merge(sub[["DFG_base", "DFG_size"]].drop_duplicates(), on="DFG_base")
    
    dfg_order = agg.sort_values("DFG_size")["DFG_base"].unique()
    piv = agg.pivot(index="DFG_base", columns="variant", values="Delta").reindex(dfg_order)

    plt.figure(figsize=(12, 6))
    x = np.arange(len(piv.index))
    
    for var in WANTED_VARIANTS_1:
        if var not in piv.columns: continue
        # Styling
        style = '--' if var == "FALLS" else '-'
        color = 'black' if var == "FALLS" else ('red' if var == "FDS" else None)
        
        plt.plot(x, piv[var], marker='o' if var != "FALLS" else None, 
                 linestyle=style, label=var, color=color)

    plt.xticks(x, piv.index, rotation=45, ha="right")
    plt.ylabel("Î” Latency (vs FALLS)")
    plt.title(f"Graph 1: Latency Delta ({mode})")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.savefig(f"Fig1_Delta_{mode}.png")
    plt.show()

def plot_runtime(df: pd.DataFrame, mode: str):
    sub = df[(df["mode"] == mode) & (df["variant"].isin(WANTED_VARIANTS_2))].copy()
    if sub.empty: return
    
    # Find time column
    time_col = next((c for c in sub.columns if "Runtime" in c or "time" in c.lower()), None)
    if not time_col: return

    plt.figure(figsize=(10, 6))
    for var in WANTED_VARIANTS_2:
        if var == "FALLS": continue
        data = sub[sub["variant"] == var].dropna(subset=["DFG_size", time_col]).sort_values("DFG_size")
        if data.empty: continue
        
        plt.scatter(data["DFG_size"], data[time_col], alpha=0.6, label=var)
        
        # Fit curve
        if len(data) > 3:
            deg = 3 if var == "FDS" else 1
            try:
                z = np.polyfit(data["DFG_size"], data[time_col], deg)
                p = np.poly1d(z)
                x_line = np.linspace(data["DFG_size"].min(), data["DFG_size"].max(), 200)
                plt.plot(x_line, p(x_line), linestyle='--', linewidth=1.5)
            except: pass

    plt.xlabel("DFG Size")
    plt.ylabel("Runtime (ms)")
    plt.title(f"Graph 2: Runtime ({mode})")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"Fig2_Runtime_{mode}.png")
    plt.show()

def plot_improvements(df: pd.DataFrame, mode: str):
    # Filter only LS variants
    sub = df[(df["mode"] == mode) & (df["alg"] == "LS")].copy()
    if sub.empty: return
    
    piv = sub.groupby(["DFG_base", "variant"])["Actual_Latency(Project)"].mean().unstack()
    
    # BASELINE IS "LS"
    if "LS" not in piv.columns:
        print(f"Skipping Graph 3 ({mode}): Baseline 'LS' not found in data.")
        return

    targets = ["LS_s0_p0", "LS_s1_p1"]
    results = []
    
    for tgt in targets:
        if tgt in piv.columns:
            # Improvement: (Baseline - Target) / Baseline * 100
            diff = (piv["LS"] - piv[tgt]) / piv["LS"] * 100
            results.append({"variant": tgt, "mean": diff.mean()})
            
    res_df = pd.DataFrame(results)
    if res_df.empty: return
    
    plt.figure(figsize=(6, 5))
    bars = plt.bar(res_df["variant"], res_df["mean"], color=['blue', 'green'])
    plt.axhline(0, color='black', linewidth=0.8)
    plt.ylabel("% Improvement vs LS (Baseline)")
    plt.title(f"Graph 3: Improvement over LS ({mode})")
    
    for bar in bars:
        h = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, h, f"{h:.2f}%", 
                 ha='center', va='bottom' if h>0 else 'top')
                 
    plt.tight_layout()
    plt.savefig(f"Fig3_Imp_{mode}.png")
    plt.show()



def plot_graph_4(df, mode):
    print(f"\nProcessing Graph 4 for mode: {mode}")
    
    subset = df[df["Mode"] == mode].copy()
    if subset.empty:
        print("  -> No data found for this mode.")
        return

    # 1. Identify Valid DFGs (Intersection)
    # We only want DFGs that successfully ran for BOTH variants across ALL factors found.
    # This prevents the average from jumping just because a hard DFG failed.
    
    # pivot: Index=DFG, Columns=(Factor, Variant)
    piv = subset.pivot_table(index="DFG", columns=["Factor", "Variant"], values="Latency")
    
    # Drop rows (DFGs) that have ANY missing value
    valid_dfgs = piv.dropna()
    print(f"  -> Valid common DFGs found: {len(valid_dfgs)} (out of {len(piv)})")
    
    if len(valid_dfgs) == 0:
        print("  -> CRITICAL: No DFGs are common across all factors. Plotting with available data (averages might be skewed).")
        # Fallback: use whatever data we have
        plot_data = subset.groupby(["Factor", "Variant"])["Latency"].mean().reset_index()
    else:
        # Calculate average latency of the valid set
        # Stack back to long format for easier grouping
        clean_long = valid_dfgs.stack(level=[0,1]).reset_index().rename(columns={0: "Latency"})
        plot_data = clean_long.groupby(["Factor", "Variant"])["Latency"].mean().reset_index()

    # 2. Plotting
    plt.figure(figsize=(10, 6))
    
    # Convert Factor to float for plotting on X-axis, but keep string labels
    plot_data["FactorVal"] = plot_data["Factor"].astype(float)
    
    for var in WANTED_VARIANTS_4:
        data = plot_data[plot_data["Variant"] == var].sort_values("FactorVal", ascending=False)
        
        # Style
        color = 'blue' if var == "LS" else 'red'
        marker = 'o' if var == "LS" else 's'
        label = "Standard LS" if var == "LS" else "Optimized LS (s1_p1)"
        
        plt.plot(data["FactorVal"], data["Latency"], marker=marker, label=label, color=color, linewidth=2)

    # Formatting
    plt.gca().invert_xaxis() # 1.00 on left, 0.10 on right
    plt.xlabel("Resource Constraint Factor (Stricter --->)")
    plt.ylabel("Average Latency (cycles)")
    plt.title(f"Graph 4: Latency Comparison under Stricter Constraints ({mode})")
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend()
    plt.tight_layout()
    
    out_file = f"Fig4_Scaling_{mode}.png"
    plt.savefig(out_file)
    print(f"  -> Saved {out_file}")
    plt.show()



# ============================================================
# MAIN
# ============================================================

def main():
    print("Loading data...")
    df = load_all_results()
    if df.empty:
        print("No data found! Check 'CSV' folder exists and has files.")
        return
        
    print(f"Variants found: {list(df['variant'].unique())}")
    
    for mode in ["uniform", "invdelay"]:
        print(f"\n--- {mode} ---")
        plot_delta(df, mode)
        plot_runtime(df, mode)
        plot_improvements(df, mode)

if __name__ == "__main__":
    main()